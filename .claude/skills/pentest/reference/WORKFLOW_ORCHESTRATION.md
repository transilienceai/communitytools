# Workflow Orchestration

**Purpose**: Structure multi-phase penetration tests with systematic progression and checkpoint management.

**When to Use**: Complex assessments (4+ hours), enterprise pentests, long-running bug bounty campaigns, or when crash recovery is critical.

---

## Core Concepts

**Pipeline**: Ordered sequence of testing stages with dependencies
**Stage**: Single testing phase (e.g., reconnaissance, exploitation)
**Checkpoint**: Saved state for resuming after interruption
**Decision Point**: AI-assisted choice on next actions based on findings

---

## Standard Pipelines

### Quick Scan (15-30 minutes)
```
Recon (passive) → Enumerate endpoints → Test critical vulns → Report
```

### Comprehensive Pentest (PTES 7-phase)
```
Pre-engagement → Intelligence gathering → Threat modeling
    ↓
Vulnerability analysis → Exploitation → Post-exploitation
    ↓
Reporting (executive + technical)
```

### Bug Bounty Campaign
```
Asset discovery → Technology fingerprinting
    ↓
Deploy 32 specialized agents in parallel
    ↓
Finding verification → PoC development → Submission
```

---

## Checkpointing Strategy

**When to Checkpoint**:
- Every 50-100 findings discovered
- After completing major phase
- Every 2 hours of testing
- Before destructive actions

**Implementation**:
```bash
# Create checkpoint
findings.json → checkpoint-TIMESTAMP.json
state.json → includes current stage, progress, metrics

# Resume from checkpoint
Load checkpoint-TIMESTAMP.json → continue from next stage
```

---

## AI-Powered Decisions

**Use AI for**:
1. **Attack Prioritization**: Which vectors to test first based on tech stack
2. **Finding Verification**: Reduce false positives before reporting
3. **Scope Adjustment**: Evaluate if discovered assets are in-scope
4. **Exploit Selection**: Choose safest/most effective exploit method

**Pattern**: Deploy Task with prompt requesting decision + context
```
Task(subagent="general-purpose",
     prompt="Given findings: [X], recommend next testing stages and reasoning")
```

---

## Parallel Agent Deployment

**When**: Comprehensive testing where speed matters

**Pattern**: Deploy all agents simultaneously, aggregate results
```
Deploy 32 agents in parallel via Pentester orchestrator
Monitor discoveries → spawn recursive agents for new findings
Verify PoCs → aggregate → deduplicate → report
```

**Agents**: See `.claude/agents/Pentester.md` reference/AGENT_CATALOG.md

---

## Progressive Testing Levels

**Level 1**: Automated scanning, known vulnerabilities
**Level 2**: Manual testing, OWASP methodologies
**Level 3**: Chain exploits, test business logic
**Level 4**: Bypass protections (WAF, rate limits)
**Level 5**: Novel techniques, zero-days

Progress through levels based on findings and time constraints.

---

## Metrics & Progress Tracking

Track during engagement:
- Total stages completed / remaining
- Findings by severity (Critical/High/Med/Low)
- Coverage percentage (% of attack surface tested)
- Time per stage (identify bottlenecks)
- PoC success rate (verified vs. total findings)

Use for prioritization and reporting.
